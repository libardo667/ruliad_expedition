import { QUALITY_PROFILES } from '../core/constants.js';
import { CALL_LOGS, CURRENT_RUN_ID, PROMPT_TEMPLATE_OVERRIDES, SOURCE_MATERIAL } from '../core/state.js';
import { clampInt, parseOptionalInt, structuredCloneSafe } from '../core/utils.js';
import { normalizeMode, providerFetch } from './provider.js';

// Auto-generated by tools/decompose.mjs â€” edit freely after generation
// Source: ruliad_expedition_v1.1.html
// Module: js/api/llm.js

export function recordCall(entry){const payload={runId:CURRENT_RUN_ID||null,timestamp:entry?.timestamp||new Date().toISOString(),...entry};CALL_LOGS.push(payload);}

export function getQualityProfile(mode){const key=(mode||"").toLowerCase();return QUALITY_PROFILES[key]||QUALITY_PROFILES.balanced;}

export function withArtifactTokenBudget(cfg,{minTokens=2800,multiplier=2,maxTokens=12000}={}){const base=getQualityProfile(cfg?.qualityMode).maxTokens;const requested=Math.max(minTokens,Math.round(base*multiplier));return {...cfg,__maxTokens:clampInt(requested,128,maxTokens)};}

export function readApiConfig(){return {
  mode:document.getElementById("api-mode").value,
  apiKey:document.getElementById("api-key-input").value.trim(),
  researchModel:document.getElementById("research-model-input").value.trim(),
  embeddingModel:document.getElementById("embedding-model-input").value.trim(),
  webSearch:Boolean(document.getElementById("web-search-check")?.checked),
  qualityMode:document.getElementById("quality-mode-select")?.value||"balanced",
  sourcePolicy:document.getElementById("source-policy-input")?.value.trim()||"",
  redTeam:Boolean(document.getElementById("redteam-check")?.checked),
  replicationModels:document.getElementById("replication-models-input")?.value.trim()||"",
  replicationRuns:clampInt(document.getElementById("replication-runs-input")?.value||1,1,5),
  replicationStrategy:document.getElementById("replication-strategy-select")?.value||"fixed",
  enableComputationalIrreducibility:Boolean(document.getElementById("ca-probe-check")?.checked),
  caRuleOverride:parseOptionalInt(document.getElementById("ca-rule-input")?.value,0,255),
  caStepsOverride:parseOptionalInt(document.getElementById("ca-steps-input")?.value,16,240),
  caWidthOverride:parseOptionalInt(document.getElementById("ca-width-input")?.value,31,401),
  promptTemplateOverrides:structuredCloneSafe(PROMPT_TEMPLATE_OVERRIDES),
  sourceText:SOURCE_MATERIAL?.text||"",
  sourceUrls:SOURCE_MATERIAL?.urls||[],
  sourceByDisc:SOURCE_MATERIAL?.byDisc||null
};}

export function validateApiConfig(cfg){if(!cfg.researchModel) return "Please enter a research model id.";if(!cfg.embeddingModel) return "Please enter an embedding model id.";if(normalizeMode(cfg)==="direct"&&!cfg.apiKey) return "Please enter an API key for direct mode.";if(normalizeMode(cfg)==="direct"&&cfg.apiKey&&!cfg.apiKey.startsWith("sk-or-")) return "Expected an OpenRouter key (starts with sk-or-).";return "";}

export function flattenContent(content){if(typeof content==="string") return content;if(Array.isArray(content)){return content.map(part=>{if(typeof part==="string") return part;if(part&&typeof part.text==="string") return part.text;return "";}).join("\n");}return "";}

export async function callLLMFull(systemPrompt,userPrompt,cfg){const quality=getQualityProfile(cfg.qualityMode);const requestedMax=Number(cfg?.__maxTokens??cfg?.maxTokens);const resolvedMax=Number.isFinite(requestedMax)?clampInt(requestedMax,128,12000):quality.maxTokens;const body={model:cfg.researchModel,max_tokens:resolvedMax,temperature:Number.isFinite(Number(cfg.__tempOverride))?Number(cfg.__tempOverride):quality.temperature,messages:[{role:"system",content:systemPrompt},{role:"user",content:userPrompt}]};if(cfg.webSearch){body.plugins=[{id:"web"}];}if(Boolean(cfg?.__jsonMode)){body.response_format={type:"json_object"};}const startedAt=new Date().toISOString();let data=null;try{data=await providerFetch("chat",body,cfg);}catch(err){const msg=String(err?.message||err||"");if(body.response_format&&/response[_\s-]?format|unsupported|not supported|invalid request|unknown parameter/i.test(msg)){delete body.response_format;data=await providerFetch("chat",body,cfg);}else{throw err;}}const text=flattenContent(data.choices?.[0]?.message?.content);recordCall({kind:"chat",timestamp:startedAt,model:body.model,temperature:body.temperature,max_tokens:body.max_tokens,webSearch:Boolean(cfg.webSearch),jsonMode:Boolean(cfg?.__jsonMode),systemPrompt,userPrompt,request:body,response:data});if(!text) throw new Error("Model returned no text content.");return {text,raw:data,request:body};}

export async function callLLM(systemPrompt,userPrompt,cfg){const out=await callLLMFull(systemPrompt,userPrompt,cfg);return out.text;}

export async function callLLMJSON(systemPrompt,userPrompt,cfg){return callLLM(systemPrompt,userPrompt,{...(cfg||{}),__jsonMode:true});}
